\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[backend=biber,style=alphabetic]{biblatex}
\usepackage{mathtools}
\usepackage{bussproofs}
\usepackage{cmll}
\usepackage{csquotes}
\usepackage{tikz-cd}
\usepackage{keytheorems}
\usepackage{todonotes}
\usepackage{xcolor}
\usepackage{hyperref}

\hypersetup{
  colorlinks=true,
  % linkcolor=cyan,
}

\newkeytheoremstyle{proof}{
  inherit-style=definition,
  qed=$\lrcorner$,
  numbered=false,
}
\newkeytheorem{theorem}[style=plain,parent=section]
\newkeytheorem{
  proposition,
  lemma,
  corollary,
  problem,
  conjecture,
}[
  style=plain,
  sibling=theorem,
]
\newkeytheorem{definition}[style=definition,sibling=theorem]
\newkeytheorem{construction}[style=proof,sibling=theorem]
\newkeytheorem{remark}[style=remark,sibling=theorem]

% A custom tikzcd arrow tip, a lollipop (âŠ¸).
% https://tex.stackexchange.com/a/730357
\tikzset{
  % See section 4.4 ("Glyph arrow tips") of the tikzcd manual.
  % multimap/.tip={Glyph[glyph math command=circ, glyph length=1.03ex, glyph shorten=-0.2ex]},
  multimap/.tip={Circle[open]},
}

\colorlet{Highlight}{purple!80!gray}
\NewDocumentCommand{\Highlight}{m}{\textcolor{Highlight}{#1}}

\title{Derivates of Containers without Decidable Equality}
\author{Philipp Joram}
\date{\today}

\addbibresource{bibliography.bib}

\DeclareMathSymbol{\shortminus}{\mathbin}{AMSa}{"39}

\newcommand*{\Op}[1]{\mathsf{#1}}
\DeclareMathOperator{\Type}{\mathsf{Type}}
\DeclareMathOperator{\W}{\mathsf{W}}
\DeclareMathOperator{\FinSet}{\Op{FinSet}}
\DeclareMathOperator{\El}{\Op{El}}
\DeclareMathOperator{\Sup}{\mathsf{sup}}
\DeclareMathOperator{\Dec}{\mathsf{Dec}}
\DeclareMathOperator{\DefEq}{\mathrel{\coloneq}}
\DeclareMathOperator{\JudgeEq}{\mathrel{\doteq}}
\NewDocumentCommand{\Inv}{}{{\shortminus 1}}

\DeclareMathOperator{\Isolate}{\Op{isolate}}
\DeclareMathOperator{\Replace}{\Op{replace}}
\DeclareMathOperator{\SigmaRemove}{\Op{\Sigma-remove}}
\DeclareMathOperator{\SigmaIsolate}{\Op{\Sigma-isolate}}

\newcommand*{\Isolated}[1]{#1^{\circ}}
\DeclareMathOperator{\Graft}{\Op{graft}}
\DeclarePairedDelimiterXPP{\GraftSyntaxX}[3]%
  {}%
  {[}%
  {]}%
  {_{#3}}%
  {#2 \delimsize\vert #1}
\DeclarePairedDelimiterX{\GraftSyntax}[2]{[}{]}{#2 \delimsize\vert #1}

\newcommand*{\MkCont}[2]{#1\mathbin{\triangleleft}#2}
\DeclareMathOperator{\Sh}{\mathsf{Sh}}
\DeclareMathOperator{\Ps}{\mathsf{Ps}}

\NewDocumentCommand{\CTimes}{}{\mathbin{\times}}
\NewDocumentCommand{\CPlus}{}{\mathbin{+}}
\DeclareMathOperator{\CConst}{\Op{K}}
\DeclarePairedDelimiterXPP{\Wk}[1]%
  {} % pre-code
  {\langle} % left
  {\rangle} % right
  {^{\uparrow}} % post-code
  {#1} % body
\newcommand*{\Subst}[2]{#1[#2]}

\NewDocumentCommand{\SimMultiMap}{}{%
  \mathrel{%
    \vbox{%
      \offinterlineskip%
      \mathsurround=0pt
      \ialign{%
        \hfil##\hfil\cr
        \normalfont\scalebox{0.9}{\kern-.33ex{$\sim$}}\cr
        \noalign{\kern-.25ex}
        $\scriptstyle\multimap$\cr%
      }%
    }%
  }%
}

\newcommand*{\Cart}[2]{#1\mathrel{\multimap}#2}
\NewDocumentCommand{\CartEquiv}{}{\multimapboth}
\newcommand*{\CartIso}[2]{#1 \mathrel{\CartEquiv} #2}

\DeclareMathOperator{\Cont}{\mathsf{Cont}}
\NewDocumentCommand{\ContCart}{}{\operatorname{\Cont}^{{\scriptscriptstyle\multimap}}}

\NewDocumentCommand{\Der}{}{\partial}
\NewDocumentCommand{\Id}{}{\mathsf{Id}}
\NewDocumentCommand{\Proj}{m}{\pi_{#1}}
\DeclareMathOperator{\Chain}{\Op{chain}}
\DeclareMathOperator{\MuRule}{\Op{\mu-rule}}

\DeclareMathOperator{\Inl}{\mathsf{inl}}
\DeclareMathOperator{\Inr}{\mathsf{inr}}

\NewDocumentCommand{\Maybe}{m}{#1 \CTimes \Id}
\DeclareMathOperator{\Nothing}{\mathsf{nothing}}
\DeclareMathOperator{\Just}{\mathsf{just}}

\makeatletter
\newcommand{\proofsubparagraph}{%
  \@startsection{subparagraph}%
  {5}%
  {\z@}%
  {3.25ex \@plus1ex \@minus .2ex}%
  {-1em}%
  {\sffamily\normalsize\bfseries}%
}
\makeatother

\begin{document}

\maketitle

\begin{abstract}
  We introduce a derivative operation for containers whose positions lack decidable equality.
\end{abstract}

\section{Introduction}

\begin{itemize}
  \item
    Two perspectives:
      \begin{itemize}
        \item \emph{(Reverse mathematics)}.
          What are the minimal assumptions on decidability that we can make such
          that a derivative is still well-defined?
        \item \emph{(Topology)}.
          If we think of types as spaces, which points can we remove in a \emph{continuous} manner?
      \end{itemize}
\end{itemize}

\section{Isolated Points and How to Remove Them}

This section recalls the notion of isolated points of a type.
This definition is not new\todo{figure out how to properly cite \texttt{TypeTopology} \cite{EscardocontributorsTypeTopology}, or whatever primary source}.
We are going to prove some properties that will be applied in \autoref{derivatives}
to establish properties of derivatives of containers:
Many of the laws of derivatives -- after some \emph{type-yoga} -- reduce directly to instances of statements in this section.

\begin{definition}
  A point \( a : A \) is \emph{isolated} if \( a = b \) is decidable for all \( b : A \).
  We denote by \( \Isolated{A} \) the subtype of isolated points, that is
  \(
    \Isolated{A} \DefEq \sum_{a : A} \prod_{b : B} \Dec(a = b)
  \).
\end{definition}

Asking for a point to be isolated trivializes the path spaces around it:
\begin{lemma}[note={\cite[Theorem~3.12]{KrausEtAl2017NotionsAnonymousExistence}}]\label{is-prop-isolated-path}
  If \( a : A \) is isolated, then \( a = b \) is a proposition for all \( b : A \).
\end{lemma}

This has a number of direct consequences which we are going to be useful in a number of constructions:
\begin{corollary}\label{is-prop-isolated-dec-path}
  If \( a : A \) is isolated, then \( \Dec{(a = b)} \) is a proposition for all \( b : A \).
\end{corollary}

\begin{corollary}\label{is-prop-is-isolated}
  Being an isolated point is a proposition.
\end{corollary}

In \cite{KrausEtAl2017NotionsAnonymousExistence}, \citeauthor{KrausEtAl2017NotionsAnonymousExistence}
state the proof of \autoref{is-prop-isolated-path} as a \enquote{local} version of Hedberg's theorem.\todo{\cite{Kraus2015TruncationLevelsHomotopy} has a nice discussion in \S 3.2.}
Perhaps, if we change our perspective, we can see Hedberg's theorem as a \emph{global} version of this:
A type whose points are all isolated is always a (homotopy) set.
This corresponds to the intuition that
a space consisting entirely of isolated points is necessarily (topologically) discrete.
In a univalent setting, however, a type can have interesting, non-trivial path types.
Its subtype of isolated points then carves out points lacking any interesting path structure:

\begin{proposition}\label{is-set-isolated}
  For any type \( A \), its type of isolated points \( \Isolated{A} \) is discrete, hence a set.
  \begin{proof}
    \( \Isolated{A} \) is vacuously discrete
    --- after all, any point comes with a way to decide equality ---
    hence its path types must be propositions.
  \end{proof}
\end{proposition}

The forgetful map \( \Isolated{A} \to A \) classifies discrete types:
\begin{lemma}\label{is-equiv-forget-isolated-iff-discrete}
  The map \( \Op{fst} : \Isolated{A} \to A \) is an equivalence if and only if \( A \) is discrete.
\end{lemma}

Being an isolated point is stable under equivalence:
\begin{lemma}\label{is-isolated-respect-equiv}
  If \( e : A \simeq B \),
  then \( a : A \) is isolated if and only if \( e(a) : B \) is isolated.
  We write \( \Isolated{e} : \Isolated{A} \simeq \Isolated{B} \) for the induced equivalence.
\end{lemma}

If a map \( f : A \to B \) is not an equivalence,
but still behaves \enquote{nicely} on path spaces, we can deduce its behavior on isolated points.
Recall that \( f \) is an embedding if \( \Op{cong}_f : x = y \to f(x) = f(y) \) is an equivalence,
written \( f : A \hookrightarrow B \).
Such maps reflect isolated points:

\begin{proposition}[note={Embeddings reflect isolated points}]\label{embedding-reflect-isolated}
  Let \( f : A \hookrightarrow B \) and \( a : A \).
  If \( f(a) \) is isolated in \( B \), then \( a \) is isolated in \( A \).
  \begin{proof}
    For all \( a^\prime : A \), we need to decide \( a = a^\prime \).
    By assumption, we can decide whether \( f(a) = f(a^\prime) \) or not.
    If \( f(a) \neq f(a^\prime) \), then necessarily \( a \neq a^\prime \).
    If \( f(a) = f(a^\prime) \), we get \( a = a^\prime \) since \( f \) is an embedding, which we can cancel.
  \end{proof}
\end{proposition}
In principle, we can weaken the assumptions of the previous proposition to a function \( f : A \to B \)
for which \emph{some} \( \prod_{x,y} f(x) = f(y) \to x = y \) exists -- not necessarily an inverse to \( \Op{cong}_f \):
the proof works no matter which path we pick,
and \emph{post hoc} this choice of path is unique, since it originates from an isolated point.

In the remainder, however, we will, apply \autoref{embedding-reflect-isolated} exclusively to embeddings.
In particular, we deduce that the canonical embeddings \( \Inl : A \hookrightarrow A + B \) and \( \Inr : B \hookrightarrow A + B \)
both reflect and create isolated points:

\begin{proposition}\label{sum-embeddings-respect-isolated}
  Let \( A, B : \Type \).
  A point \( a : A \) is isolated if and only if \( \Inl{(a)} : A + B \) is isolated;
  similarly for \( b : B \) and \( \Inr{(b)} : A + B \).
  \begin{proof}
    Let \( a : A \). In the forward direction, assume that \( a \) is isolated.
    We need to show that for any \( x : A + B \), the type \( \Inl{a} = x \) is decidable.
    Consider the case of \( x \JudgeEq \Inl{a^{\prime}} \).
    We know that \( \Inl \) is an embedding, and as such there is an equivalence
    of path spaces \( (\Inl{a} = \Inl{a^\prime}) \simeq (a = a^\prime) \).
    But \( (a = a^\prime) \) is decidable by assumption,
    hence \( (\Inl{a} = \Inl{a^\prime}) \) is decidable.
    In case \( x \JudgeEq \Inr{b} \), the type \( \Inl{a} = \Inr{b} \) is empty, hence decidable.
    For the converse, apply \autoref{embedding-reflect-isolated}:
    The map \( \Inl \) is an embedding, and as such reflects isolated points.
  \end{proof}
\end{proposition}

We see that isolated points distribute over sums:
\begin{problem}\label{isolated-sum-equiv}
  Construct an equivalence \( \Isolated{(A + B)} \simeq \Isolated{A} + \Isolated{B} \).
  \begin{construction}
    Define the obvious forward- and backward maps by case analysis,
    and prove that points are isolated using \autoref{sum-embeddings-respect-isolated}.
    That these maps are mutually inverse follows since being isolated is a proposition (\autoref{is-prop-is-isolated}).
  \end{construction}
\end{problem}

From this we immediately see that \( \Nothing \DefEq \Inr{(\bullet)} : A + 1 \) is an isolated point, since \( \bullet : 1 \)
is trivially isolated:

\begin{corollary}\label{is-isolated-nothing}
  The point \( \Nothing : A + 1 \) is isolated for any type \( A \),
  and there is an equivalence \( \Isolated{(A + 1)} \simeq \Isolated{A} + 1 \).
\end{corollary}

While it may seem obvious that the isolated points of a disjoint sum are a sum of isolated points,
describing the isolated points of \( \Sigma \)-types is a more subtle affair.
Later on (\autoref{lax-chain-rule}),
it will become necessary to investigate whether isolated points distribute over other type formers,
in particular dependent sums.\todo{Put this sentence into the introduction}
First, observe that any dependent pair of isolated points defines an isolated point in the corresponding \( \Sigma \)-type:
\begin{proposition}\label{is-isolated-pair}
  Let \( A : \Type \) and \( B : A \to \Type \) with points \( a_0 : A \) and \( b_0 : B(a_0) \).
  If both \( a_0 \) and \( b_0 \) are isolated, then \( (a_0 , b_0) \) is isolated in \( \sum_{a : A} B(a) \).
  This defines a map
  \[
    \SigmaIsolate_{A,B} :
      \sum\nolimits_{a_0 : \Isolated{A}} \Isolated{B(a_0)}
        \to
      \Isolated{%
        \big(
          \sum\nolimits_{a : A} B(a)
        \big)
      }.
  \]
  \begin{proof}
    Let \( a : A \), \( b : B(a) \). Our goal is to decide whether \( (a_0 , b_0) = (a, b) \) or not.
    By extensionality of path types of dependent sums
    it suffices to decide the equivalent type \( \sum_{p : a_0 = a} b_0 = \Op{subst}_B(p^{\Inv}, b_0) \).
    If \( a_0 \neq a \), then this type is empty.
    Otherwise, we have some \( p : a_0 = a \), and the type is inhabited or empty
    depending on whether \( b_0 = \Op{subst}_B(p^{\Inv}, b_0) \) or not.
  \end{proof}
\end{proposition}

If we had an inverse to \( \SigmaIsolate \), then the converse would hold as well.
It turns out that this requirement is not only sufficient, but also necessary:

\begin{lemma}\label{is-equiv-sigma-isolate-iff-isolated-pair}
  Let \( A : \Type \) and \( B : A \to \Type \).
  The following are equivalent:
  \begin{enumerate}
    \item \label{is-equiv-sigma-isolate-iff-isolated-pair-is-equiv}
      \( \SigmaIsolate_{A,B} \) is an equivalence.
    \item \label{is-equiv-sigma-isolate-iff-isolated-pair-pair}
      For all \( a_0 : A \) and \( b_0 : B(a_0) \),
      if \( (a_0 , b_0) \) is isolated in \( \Sigma_{A} B \),
      then both \( a_0 \) and \( b_0 \) are isolated.
  \end{enumerate}
  \begin{proof}
    The first implies the second as follows:
    Assume that \( \SigmaIsolate_{A,B} \) is an equivalence with inverse
    \( u : \Isolated{\big(\sum_{a : A} B(a)\big)} \to \sum_{a : \Isolated{A}} \Isolated{B(a)} \).
    Let \( a_0 : A \), \( b_0 : B(a_0) \), and \( h_0 : \Op{isIsolated}{(a_0, b_0)} \).
    Apply \( u \) to get some \( y \DefEq u((a_0 , b_0) , h_0) \)
    with components \( y \JudgeEq ((a, h_a), (b, h_b)) \).
    Note that \( h_a \) and \( h_b \) are proofs that \( a \) and \( b \) are isolated, respectively.
    We are done if we can show that \( p : a_0 = a \) and \( \cramped{b_0 =_{p} b} \),
    since transport along these paths preserves isolated points.
    Indeed, both \( \SigmaIsolate(y) \JudgeEq ((a, b), \mathunderscore) \) and \( ((a_0, b_0), p_0) \)
    lie in \( \Op{fiber}_u(y) \), which is necessarily contractible,
    hence \( (a_0 , b_0) = (a, b) \) as desired.

    In the other direction, the assumption provides the missing properties to define a tentative inverse to \( \SigmaIsolate \);
    that this is the correct inverse follows as being isolated is a proposition (cf.~\autoref{is-prop-is-isolated}).
  \end{proof}
\end{lemma}

For discrete \( A : \Type \) and \( B : A \to \Type \),
\autoref{is-equiv-forget-isolated-iff-discrete} tells us that isolated points trivially distribute over sums;
there is an equivalence
\( \sum_{a_0 : \Isolated{A}} \Isolated{B(a_0)} \simeq \sum_{a : A} B(a) \simeq \cramped{ \Isolated{\big(\sum_{a : A} B(a)\big)} } \).
The previous result confirms that the map underlying this equivalence is \( \SigmaIsolate \):

\begin{corollary}\label{discrete-is-equiv-sigma-isolated}
  If \( A : \Type \) and \( B : A \to \Type \) are (pointwise) discrete types,
  then \( \SigmaIsolate_{A,B} \) is an equivalence.
  \begin{proof}
    Condition \ref{is-equiv-sigma-isolate-iff-isolated-pair-pair} of \autoref{is-equiv-sigma-isolate-iff-isolated-pair} is vacuously satisfied for discrete types.
  \end{proof}
\end{corollary}

In general, however, it seems difficult to describe exactly when isolated points distribute this way.
In extreme cases, both \( A \) and \( B \) can be complicated types, whereas their sum \( \sum_A B \) is entirely trivial.
This applies in particular to the type of singletons, \( \Op{singl}(a_0) \DefEq \sum_{a : A} a_0 = a \):
\begin{proposition}\label{discrete-iff-is-equiv-singl-isolate}
  For all types \( A \), following are equivalent:
  \begin{enumerate}
    \item \( A \) is discrete.
    \item For all \( a_0 : A \), the map
      \(
        \SigmaIsolate_{A, a_0 = {(\shortminus)}} : \sum_{a : \Isolated{A}} \Isolated{(a_0 = a)} \to \Isolated{\Op{singl}(a_0)}
      \)
      is an equivalence.
  \end{enumerate}
  \begin{proof}
    If \( A \) is discrete, then so are its path types, hence \( \SigmaIsolate_{A, a_0 = (\shortminus)} \) is an equivalence by \autoref{discrete-is-equiv-sigma-isolated}.
    In the other direction, we can show that every \( a_0 : A \) is isolated:
    Since \( \Op{singl}(a_0) \) is a contractible type, its center \( (a_0, \Op{refl}) \) is isolated.
    Thus, by \autoref{is-equiv-sigma-isolate-iff-isolated-pair}, the first component \( a_0 \) must be isolated.
  \end{proof}
\end{proposition}
This lets us describe whether a type is discrete purely in terms of \( \SigmaIsolate \),
which will be useful in situations in which we have control over the types indexing \( \SigmaIsolate \).

\todo[inline]{This result is not used anywhere, but might be of independent interest.}
\begin{proposition}
  Let \( A : \Type \), \( B : A \to \Type \), and \( a : \Isolated{A} \).
  Then any \( b : B(a) \) is isolated if and only if \( (a, b) : \sum_{A} B \) is isolated.
\end{proposition}

\subsection{Removing points}


For any type \( A \) and point \( a_0 : A \) we define the subtype of \enquote{\( A \) with \( a_0 \) removed}
to be \( A \setminus a_0 \DefEq \sum_{a : A} a_0 \neq a \).
Adding a point to a type \( A \) and then removing it again yields an equivalence, as expected:
\begin{problem}\label{maybe-minus-nothing-equiv}
  Define an equivalence \( (A + 1) \setminus \Nothing \simeq A \).
  % \begin{construction}
  %   Define \( f : (A + 1) \setminus \Nothing \to A \) as \( f(\Just{a} , \mathunderscore) \DefEq a \);
  %   the case \( f(\Nothing, h : \Nothing \neq \Nothing) \) is absurd.
  %   It is straightforward to show that the fibers of \( f \) are contractible.
  % \end{construction}
\end{problem}

This is an instance of the more general case where removing a point from a sum
is the same as removing it from either side, and then taking the sum:
\begin{problem}\label{sum-remove-equiv}
  Given \( A, B : \Type \), define equivalences
  \begin{align*}
    (A + B) \setminus \Inl(a_0) &\simeq (A \setminus a_0) + B \\
    (A + B) \setminus \Inr(b_0) &\simeq A + (B \setminus b_0)
  \end{align*}
  for all points \( a_0 : A \) and \( b_0 : B \), respectively.
  \begin{construction}
    Define the obvious maps in either direction by case-analysis.
    These preserve inequalities since \( \Inl \) and \( \Inr \) are embeddings,
    and are inverses of each other as inequalities are always propositions.
  \end{construction}
\end{problem}

\begin{construction}[note={for \autoref{maybe-minus-nothing-equiv}}]
  The type \( (1 \setminus \bullet) \) is empty,
  so by \autoref{sum-remove-equiv}, \( (A + 1) \setminus \Nothing \simeq A + (1 \setminus \bullet) \simeq A \).
\end{construction}

If we would like to \emph{first remove} a point \( a_0 : A \), and \emph{then add} it back into the type,
there is an obvious map \( \Replace_{a_0} : (A \setminus a_0) + 1 \to A \);
it is defined by cases
as
\(
  \Replace_{a_0}(\Just{(a, \mathunderscore)}) \DefEq a
\)
and
\(
  \Replace_{a_0}(\Nothing) \DefEq a_0
\).
Classically, this map is an isomorphism of sets;
the inverse simply maps \( a_0 \) to \( \bullet \).
In a univalent setting however, \( a_0 \) might have interesting (higher) path spaces,
which too are removed by this construction.
Consider for example the circle \( S^1 \) with \( \mathsf{base} : S^1 \).
Then \( S^1 \setminus \mathsf{base} \simeq 0 \),
hence \( (S^1 \setminus \mathsf{base}) + 1 \simeq 1 \not\simeq S^1 \):
removing \( \mathsf{base} \) removes the entire circle, which is \emph{not} contractible.
% This intui

We observe that we can replicate the classical behavior exactly when \( a_0 \) is an isolated point:

\begin{proposition}\label{isolated-minus-plus-equiv}
  Let \( a_0 : A \).
  The map \( \Replace_{a_0} \) is an equivalence typed \( (A \setminus a_0) + 1 \simeq A \)
  if and only if \( a_0 \) is isolated in \( A \).
  \begin{proof}
    First, assume that \( a_0 \) is isolated.
    We give a two-sided inverse \( g : A \to (A \setminus a_0) + 1 \) as follows.
    Define \( \Op{r} : \prod_{a : A} \Dec{a_0 = a} \to (A \setminus a_0) + 1 \)
    by
    \[
      \Op{r}(a, d) \DefEq
      \begin{cases}
        \Nothing & \text{if}\ d \JudgeEq \Op{yes}(\mathunderscore : a_0 = a) \\
        \Just{(a, h)} & \text{if}\ d \JudgeEq \Op{no}(h : a_0 \neq a)
      \end{cases}
    \]
    For \( i_0 : \Op{isIsolated}(a_0) \), let \( g(a) \DefEq \Op{r}(a, i_0(a)) \).
    By \autoref{is-prop-isolated-dec-path}, \( \Dec(a_0 = a) \) (the type of \( i_0(a) \)) is a proposition for all \( a : A \);
    we use this to ensure that \( g \) computes correctly:
    \begin{align*}
      g(a_0) &\JudgeEq \Op{r}(a_0, \Highlight{i_0(a_0)}) = \Op{r}(a_0, \Highlight{\Op{yes}(\Op{refl})}) \JudgeEq \Nothing \\
      g(a)   &\JudgeEq \Op{r}(a, \Highlight{i_0(a)}) = \Op{r}(a, \Highlight{\Op{no}(h))} \JudgeEq \Just{(a, h)}
        \quad \text{where}~h : a_0 \neq a
    \end{align*}
    Hence \( {\Replace_{a_0}} \circ g = \Op{id} \) and \( g \circ {\Replace_{a_0}} = \Op{id} \).

    For the converse, assume that \( \Replace_{a_0} \) is an equivalence.
    By \autoref{is-isolated-nothing}, \( \Nothing \) is isolated in \( (A \setminus a_0 ) + 1 \),
    so \autoref{is-isolated-respect-equiv} tells us that \( \Replace_{a_0}(\Nothing) \JudgeEq a_0 \) is isolated as well.
  \end{proof}
\end{proposition}

If we think of \( (+) \) as the binary version of an \( A \)-indexed sum \( \sum_{a : A} B(a) \),
removal of points from the latter behaves similarly,
except that we have to put some restrictions on the paths of the indexing type \( A \):
\begin{problem}\label{sigma-remove}
  Let \( A : \Type \) and \( B : A \to \Type \)
  with points \( a_0 : A \) and \( b_0 : B(a_0) \),
  and assume \( p : \Op{isProp}(a_0 = a_0) \).
  There is a map
  \[
    \operatorname{\Op{\Sigma-remove}}_p :
    \big(\smashoperator{\sum_{a : A \setminus a_0}} B(a)\big) + \big(B(a_0) \setminus b_0\big)
      \to
    \big(\sum_{a : A} B(a) \big) \setminus (a_0 , b_0)
  \]
  \begin{construction}
    We define \( \operatorname{\Op{\Sigma-remove}}_p(x) \) by cases.
    Let
    \[
      \SigmaRemove_p(\Inl{(a, h_a, b)}) \DefEq ((a, b) , h^\prime_a),
    \]
    where \( h^\prime_a : (a_0 , b_0) = (a, b) \xrightarrow{\Op{cong}_{\Op{fst}}} a_0 = a \xrightarrow{h_a} \bot \).
    In the other case, let
    \[
      \SigmaRemove_p(\Inr{(b, h_b)}) \DefEq ((a_0, b) , h^\prime_b),
    \]
    and show \( h^\prime_b : (a_0 , b_0) \neq (a_0 , b) \) as follows:
    Assume to the contrary that \( p_b : (a_0 , b_0) = (a_0 , b) \).
    From this we obtain (dependent) paths \( p_b^1 : a_0 = a_0 \) and \( p_b^2 : b_0 =_{p_b^1} b \).
    Since \( a_0 = a_0 \) is a proposition, we know that \( p_b^1 = \Op{refl} \),
    hence \( b_0 = b \).
    This is contradictory since we are given \( h_b : b_0 \neq b \).
  \end{construction}
\end{problem}
\todo[inline]{The assumption \( \Op{isProp}(a_0 = a_0) \) is called \enquote{\( h \)-isolated} in \cite[\texttt{UF.Sets}]{EscardocontributorsTypeTopology}.}

This map is an equivalence whenever we can decide if we are removing from a chosen index \( a_0 \):
\begin{proposition}\label{is-equiv-sigma-remove}
  Let \( A : \Type \), \( B : A \to \Type \) with \( a_0 : A \) and \( b_0 : B(a_0) \).
  If \( a_0 \) is an isolated point of \( A \), then \( \SigmaRemove \) of \autoref{sigma-remove}
  is an equivalence.
  \begin{proof}
    First note that \( a_0 = a_0 \) is a proposition by \autoref{is-prop-isolated-path},
    thus the map is well-defined.
    We construct an inverse
    \[
      \SigmaRemove^{\Inv}
        :
      \Big(\sum_{a : A} B(a) \Big) \setminus (a_0 , b_0)
        \to
      \Big(\smashoperator{\sum_{a : A \setminus a_0}} B(a)\Big) + \big(B(a_0) \setminus b_0\big)
    \]
    as follows:
    Introduce \( a : A \), \( b : B(a) \) and \( h : (a_0 , b_0) \neq (a , b) \),
    then decide whether \( a_0 = a \) or not.
    If \( p : a_0 = a \), we map to \( \Inr{(\Op{subst}_B(p, a), h^\prime)} \),
    where \( h^\prime : b_0 \neq \Op{subst}_B(p, a) \),
    which we conclude from \( h \) and \( p \).
    In case that \( h : a_0 \neq a \) we map to \( \Inl{((a, h), b)} \) directly.
  \end{proof}
\end{proposition}

\begin{tikzpicture}
  % \filldraw[
  %   rounded corners=10pt,
  %   fill=blue!30,
  %   draw=blue!80!black,
  %   thick,
  % ]
  %   (0,0) rectangle (7,4);

  \coordinate (O) at (-0.5,-0.5);

  \draw[->] (O) -- ++(0,1) node[above] {\( b : B(a) \)};
  \draw[->] (O) -- ++(1,0) node[right] {\( a : A \)};

  \foreach \x/\X in {0/6, 1/3, 2/5, 3/1, 4/4, 5/7} {
    \foreach \y in {1,...,\X} {
      \fill[black] (0.5+\x, \y*0.5) circle (2pt);
    }
  }
\end{tikzpicture}

\subsection{Grafting}

In order to derive the chain rule for derivatives,
\citeauthor{AbbottEtAl2005DataDifferentiating}~\cite{AbbottEtAl2005DataDifferentiating} investigate functions \( f : A \setminus a \to B \) that are defined on all but one inputs.
They call the process of extending \( f \) to all of \( A \) \emph{grafting}.
We have seen that in the presence of higher types, removal is only well-behaved for isolated points.
In order to obtain a good notion of grafting, we have to adjust the definitions accordingly.
In particular, we derive an induction principle for types
\( A \) with a chosen isolated point \( a_0 : \Isolated{A} \):
Functions out of \( A \) are exactly those out of \( A \setminus a_0 \), plus a chosen point \( b_0 : B \).
First, we define \emph{grafting}:
\begin{problem}
  For types \( A \) and \( B \), construct a function
  \[
    \Graft : \prod_{a_0 : \Isolated{A}}
      \big((A \setminus a_0 \to B) \times B \big)
        \to
      (A \to B)
  \]
\end{problem}
\begin{construction}
  Let \( a_0 : \Isolated{A} \), \( f : A \setminus a_0 \to B \) and \( b_0 : B \).
  Decide equality with \( a_0 \) to define \( \Graft_{a_0}(f, b_0) : A \to B \) as follows:
  \[
    \Graft_{a_0}(f, b_0) \DefEq
    \lambda a.\,
    \begin{cases}
      f(a, h) & \text{if}\ (h : a_0 \neq a) \\
      b_0 & \text{otherwise}
    \end{cases}
    \qedhere
  \]
\end{construction}

We adopt the notation
\( \GraftSyntaxX{f}{b_0}{a_0} \DefEq \Graft_{a_0}(f, b_0) \)
of \citeauthor{AbbottEtAl2005DataDifferentiating},
or simply \( \GraftSyntax{f}{b_0} \) if \( a_0 : \Isolated{A} \) is understood from context.

\begin{proposition}[note={\( \Graft \)-induction}]\label{graft-equiv}
  For \( A : \Type \) with \( a_0 : \Isolated{A} \),
  grafting has the following properties:
  \begin{enumerate}
    \item (Computation rules). For all \( f : A \setminus a_0 \to B \) and \( b_0 : B \):
      \begin{align*}
        \GraftSyntaxX{f}{b_0}{a_0}(a_0) &= b_0
          &
        &\text{and}
          &
        \adjustlimits \prod_{a : A} \prod_{h : a_0 \neq a} \GraftSyntaxX{f}{b_0}{a_0}(a) &= f(a, h)
      \end{align*}
    \item
      \(
        \Graft_{a_0} :
        \big((A \setminus a_0 \to B) \times B \big)
          \simeq
        (A \to B)
      \)
      is an equivalence of types.
  \end{enumerate}
  \begin{proof}
    The computation rules are straightforward, but crucially make use of \autoref{is-prop-isolated-dec-path}:
    the type \( \Dec(a_0 = a) \) is a proposition for all \( a \), and \( \Graft \) is defined by induction on this type.
    To show that \( \Graft \) is an equivalence, consider that any \( f : A \to B \) can be split
    into \( f \circ \Op{fst} : A \setminus a_0 \to B \) and \( f(a_0) : B \);
    the computation rules ensure that this is an inverse to \( \Graft \).
  \end{proof}
\end{proposition}

\section{Derivatives of Containers}\label{derivatives}

\begin{definition}
  A \emph{container} \( (\MkCont{S}{P}) \) consists of \emph{shapes} \( S : \Type \) and
  a family \( P : S \to \Type \) of \emph{positions}.
  We access shapes and positions via postfix projections
  \( (\MkCont{S}{P})_{\Sh} \DefEq S \) and \( (\MkCont{S}{P})_{\Ps} \DefEq P \).
\end{definition}

\begin{definition}
  Let \( F \JudgeEq (\MkCont{S}{P}) \) and \( G \JudgeEq (\MkCont{T}{Q}) \).
  The type of \emph{cartesian morphisms} between \( F \) and \( G \) is
  \[
    \Cart{F}{G} \DefEq \sum_{f : S \to T} \prod_{s : S} Q_{fs} \simeq P_s
  \]
\end{definition}

In the remainder of this paper we will only consider cartesian morphisms.
We are going to drop \enquote{cartesian} in writing, but retain the notation \( \Cart{F}{G} \).
Morphisms of containers compose as expected, and together with an identity morphism \( \Op{id}_F : \Cart{F}{F} \)
they form a wild category \( \ContCart \):
composition is associative and unital, but we make no assumption on the truncation level of the hom-types \( \Cart{F}{G} \).
Note that this wild category is \emph{not} univalent in the na{\"i}ve sense:
The canonical map taking identifications of containers \( F = G \) to (categorical) isomorphisms
(i.e. pairs \( f : \Cart{F}{G}, g : \Cart{G}{F} \) with chosen identifications \( fg = \Op{id}_F \) and \( gf = \Op{id}_G \)),
is \emph{not} an equivalence, unless shapes and positions of the involved containers are sets.
Instead, we are going to use the following definition when comparing containers:

\begin{definition}
  A cartesian morphism \( (f, u) : \Cart{F}{G} \) is an \emph{equivalence} of containers
  if \( f : F_{\Sh} \to G_{\Sh} \) is an equivalence of types.
  We write \( F \CartEquiv G \) for the type of equivalences of containers.
\end{definition}
By an application of univalence, the type of equivalences \( F \CartEquiv G \) is equivalent to the type of identifications, \( F = G \).
While we cannot prove this internally, we think of the wild category of containers as \( (\infty,1) \)-category
in which \( F \CartEquiv G \) is the \enquote{correct} notion of weak equivalence,
representing the \( \infty \)-groupoid of paths \( F = G \).

In cases where we do care about the truncation level of shapes and positions,
we define the following subtypes of containers:
\begin{definition}
  A container \( (\MkCont{S}{P}) \) is \( (n,k) \)-truncated if \( S \) is \( n \)-truncated,
  and \( P_s \) is \( k \)-truncated for all \( s : S \).
  Write \( \ContCart_{n,k} \) for the wild subcategory of \( (n,k) \)-truncated containers.
\end{definition}
Traditional set-based containers are \( (0,0) \)-truncated, whereas \citeauthor{Gylterud2011}'s \emph{symmetric containers}~\cite{Gylterud2011} are \( (1,0) \)-truncated.
In particular, \( (0,0) \)-truncated containers form a univalent 1-category.

When constructing a morphism \( f : \Cart{F}{G} \), we will oftentimes factor it
through (equivalent) auxiliary containers
\begin{equation*}
  \begin{tikzcd}
    F \ar[r, -multimap, "f"] & G \\
    {F'} \ar[r, -multimap, "f'"{swap}] & {G'}
    \ar[from=1-1,to=2-1, -multimap, "\sim"{swap}]
    \ar[from=2-2,to=1-2, -multimap, "\sim"{swap}]
  \end{tikzcd}
\end{equation*}
This lets us separate the bureaucracy of bringing \( F \) and \( G \) into a comparable shape
from the act of defining an interesting morphism \( f' : \Cart{F'}{G'} \).
As a consequence, \( f \) is an equivalence of containers if and only if \( f' \) is,
which is often easier to characterize.

\subsection{Derivatives}

\begin{itemize}
  \item
    Introduce derivative by its universal property:
    The derivative of \( G \) represents \enquote{\( G \) with a position removed, for each shape},
    so cartesian morphisms into \( \Der{G} \) should correspond to morphisms into \( G \) that \enquote{avoid}
    these positions.
    Traditionally, this is done by looking for adjunction \( \Maybe{(-)} \dashv \Der \):
    If such an adjunction exists, then morphisms \( \Cart{F}{\Der{G}} \) are in 1-to-1 correspondence with morphisms of shape \( (f, u) : \Cart{\Maybe{F}}{G} \).
    On positions, these are equivalences \( u_s : G_{\Ps}(fs) \simeq F_{\Ps}(s) + 1 \),
    i.e.\@ linear maps that \enquote{avoid} the chosen position \( u_s^{\Inv}(\Inr(\bullet)) : G_{\Ps}(fs) \).
  \item
    In a univalent setting, \enquote{avoiding a position} becomes more subtle:
    a position \( q : G_{\Ps}(t) \) is no longer a discrete point, but comes with a potentially complicated type of paths around it.
    If we wanted to encode morphisms into \( \Der{G} \) the same way, we would have to avoid the entire connected component around \( q \),
    that is, find some type of \enquote{hole} \( H(q) \) such that \( G_{\Ps}(fs) \simeq F_{\Ps}(s) + H(q) \).
    But this type now depends on \( q \) and its higher path structure,
    and can no longer be expressed uniformly as a simple tensoring with the fixed container \( \Id \).
  \item
    Two solutions: derivatives are no longer adjoints to tensoring with \( \Id \),
    or we only take derivatives with respect to positions that are more homogeneous.
  \item
    We take the second approach, and define a derivative in terms of \emph{isolated} positions.
  \item
    \emph{(For the conclusion)}.
    In \cite{AbbottEtAl2003DerivativesContainers}, \citeauthor{AbbottEtAl2003DerivativesContainers} consider the general adjunction \( - \CTimes H \dashv [H, -] \),
    perhaps we can make more progress towards that? By iterating ours, it should be possible to derive \( - \CTimes \Op{K}(n) \dashv \Der^n \).
    For combinatorial species, this is enough to derive the fully general adjunction, since (1) the \( \Op{K}(n) \) are exactly the representables
    \( \Op{y}(n) \), (2) every species is a colimit of some \( \Op{y}(n_i) \)'s, and (3) the product (in this case, Day-convolution) is co-continuous.
\end{itemize}

\begin{definition}
  The derivative of a container \( \Der{(\MkCont{S}{P})} \DefEq (\MkCont{S'}{P'}) \)
  has shapes \( S' \DefEq \sum_{s : S} \Isolated{P_s} \) and positions \( P'(s , p) \DefEq P_s \setminus p \).
\end{definition}

\begin{corollary}
  For \( n \geq 0 \) and \( k \geq -1 \), the derivative of an \( (n, k) \)-truncated container is \( (n, k) \)-truncated.
\end{corollary}
\begin{proof}
  Let \( (\MkCont{S}{P}) \) an \( (n, k) \)-truncated container.
  By \autoref{is-set-isolated} \( \Isolated{P_s} \) is a 0-truncated type and \( S \) is \( n \)-truncated,
  thus \( \Der{(\MkCont{S}{P})}_{\Sh} \JudgeEq \sum_{s : S} \Isolated{P_s} \) is \( n \)-truncated.
  Positions are \( k \)-types since \( P_s \setminus p \) embeds into \( P_s \).
\end{proof}

The derivative acts on cartesian morphisms.
\begin{problem}
  Define a wild endofunctor \( \Der : \ContCart \to \ContCart \).
  That is,
  for all \( f : \Cart{F}{G} \), a morphisms \( \Der{f} : \Cart{\Der{F}}{\Der{G}} \),
  such that \( \Der(\Id_F) = \Id_{\Der{F}} \) and \(\Der(fg) = (\Der{f})(\Der{g}) \).
  \begin{construction}
    For any \( (f, u) : \Cart{(\MkCont{S}{P})}{(\MkCont{T}{Q})} \),
    there is a canonical morphism \( \Der{(f, u)} \DefEq (f' , u') : \Cart{\Der{(\MkCont{S}{P})}}{\Der{(\MkCont{T}{Q})}} \)
    obtained as follows:
    On shapes, the map \( f' : \sum_{s : S} \Isolated{P_s} \to \sum_{t : T} \Isolated{G_t} \)
    applies \( f \) to the first component and \( \Isolated{(u_s^\Inv)} : \Isolated{P_s} \simeq \Isolated{G_{fs}} \) to the second.
    On positions, \( u'_{s,p} : G_{fs} \setminus u_s^\Inv(p) \simeq F_s \setminus p \) is obtained from \( u_s \), which respects the removed point \( p \).
    (cf.\@ \autoref{is-isolated-respect-equiv}).
  \end{construction}
\end{problem}


\subsection{Linear adjunction}

\begin{problem}
  Define a wild adjunction \( (\eta, \varepsilon) : (\Maybe{-}) \dashv \Der{(-)} \),
  that is:
  \begin{enumerate}
    \item
      Two families of morphisms
      \[
        \eta : \prod_{F : \Cont} \Cart{F}{\Der{(G \CTimes \Id)}}
        \quad\text{and}\quad
        \varepsilon : \prod_{G : \Cont} \Cart{\Der{G} \CTimes \Id}{G}
      \]
    \item with identifications for all \( f : \Cart{F}{G} \), showing naturality
      \[
        \operatorname{\Op{isNat}}_{\eta}(f) : \eta_F ; \Der{(f \CTimes \Id)} = f ; \eta_G
        \quad\text{and}\quad
        \operatorname{\Op{isNat}}_{\varepsilon}(f) : (\Der{f} \CTimes \Id) ; \varepsilon_G = \varepsilon_F ; f
      \]
    \item for which the zigzag-equations
      \begin{align*}
        &
        \begin{tikzcd}[ampersand replacement=\&, column sep=tiny, row sep=large]
          \Maybe{F} \& \& \Maybe{F} \\
                    \& \Maybe{(\Der{(\Maybe{F})})} \& %
          \ar[from=1-1, to=1-3, -multimap, "\Op{id}"]
          \ar[from=1-1, to=2-2, -multimap, "\Maybe{{\eta_F}}"{'}]
          \ar[from=2-2, to=1-3, -multimap, "\varepsilon_{\Maybe{F}}"{'}]
        \end{tikzcd}
          &\text{and}
        &
        \begin{tikzcd}[ampersand replacement=\&, column sep=tiny, row sep=large]
                    \& \Der{(\Maybe{\Der{G}})} \& \\
          \Der{G} \& \& \Der{G} %
          \ar[from=2-1, to=2-3, -multimap, "\Op{id}"]
          \ar[from=2-1, to=1-2, -multimap, "\eta_{\Der{G}}"]
          \ar[from=1-2, to=2-3, -multimap, "\Der{(\varepsilon_{G})}"]
        \end{tikzcd}
      \end{align*}
      hold.
  \end{enumerate}
  \begin{construction}
    Let \( F \JudgeEq (\MkCont{S}{P}) \) and define \( \eta_F : \Cart{F}{\Der{(\Maybe{F})}} \).
    On shapes, \( {\eta_F^{\Sh}} : S \to \sum_{(s, \mathunderscore) : S \times 1} \Isolated{(P_s + 1)} \)
    sends \( s \) to \( (s, \bullet) \) and \( \mathsf{nothing} \);
    the latter is isolated by \autoref{is-isolated-nothing}.
    On positions, define \( \eta_F^{\Ps} : \prod_{s : S} (P_s + 1) \setminus \Nothing \simeq P_s \)
    as in \autoref{maybe-minus-nothing-equiv}.

    Let \( G \JudgeEq (\MkCont{T}{Q}) \); define the counit \( \varepsilon_G : \Cart{\Maybe{(\Der{G})}}{G} \) as follows:
    on shapes, \( \varepsilon_G^{\Sh} : \sum_{t : T} \Isolated{Q_t} \times 1 \to T \) is the first projection.
    On positions the equivalence
    \(
      \varepsilon_G^{\Ps}(t , q) : Q_t \simeq (Q_t \setminus q) + 1
    \)
    is given by \autoref{isolated-minus-plus-equiv} for all \( t : T \) and \( q : \Isolated{Q_t} \).

    To construct the identifications for the zigzag equations,
    we apply the necessary extensionality principles for functions, equivalences and sum types.
    We are left to construct paths that are almost \( \Op{refl} \);
    only some proofs of isolation and removal need to be compared up to propositional equality.
    Construction of the naturality squares for \( \eta \) and \( \varepsilon \) is done similarly.
  \end{construction}
\end{problem}

If we restrict the above to set-truncated containers, we can solve a problem left open by \citeauthor{AbbottEtAl2005DataDifferentiating}:
they \enquote{leave it to future work to identify the subcategory of differentiable containers}~\cite[14]{AbbottEtAl2005DataDifferentiating};
indeed, \emph{every} container is differentiable in this sense, as long as we define derivatives in terms of isolated positions:
\begin{theorem}
  In the 1-category of set-truncated containers \( \ContCart_{0,0} \), \( \Der \) is right-adjoint to tensoring with \( \Id \).
\end{theorem}

\subsection{Laws of Derivates}

\begin{proposition}\label{derivative-prop-trunc}
  Let \( S : \Type \) and \( P : S \to \Op{Prop} \).
  There is an equivalence of containers
  \[
    { \Der{(\MkCont{S}{P})} }
      \CartEquiv
    { (\MkCont{{\textstyle \sum_{S} P }}{0}) }
  \]
  In particular, we have \( \Der{(\MkCont{1}{P})} \CartEquiv (\MkCont{P}{0}) \) and
  \( \Der{(\Id)} \CartEquiv (\MkCont{1}{0}) \).
  \begin{proof}
    Since \( P_s \) is a proposition, we know that \( \Isolated{P_s} \simeq P_s \) and \( P_s \setminus p \simeq 0 \).
    Thus,
    \begin{align*}
      \Der{(\MkCont{S}{P})}
        &\CartEquiv (\MkCont{((s, p) : \textstyle\sum_{s : S} \Isolated{P_s})}{P_s \setminus p})
          \\
        &\CartEquiv (\MkCont{((s, p) : \textstyle\sum_{s : S} P_s)}{0})
          \qedhere
    \end{align*}
  \end{proof}
\end{proposition}

\begin{proposition}\label{sum-product-rule}\label{sum-rule}\label{leibniz-rule}
  For containers \( F, G \), the following hold:
  \begin{enumerate}
    \item Sum rule: \( {\Der{(F \oplus G)}} \CartEquiv {\Der{F} \oplus \Der{G}} \)
    \item Leibniz rule: \( {\Der{(F \CTimes G)}} \CartEquiv {(\Der{F} \CTimes G) \oplus (F \CTimes \Der{G})} \)
  \end{enumerate}
  \begin{proof}
    Let \( F \JudgeEq (\MkCont{S}{P}) \) and \( G \JudgeEq (\MkCont{T}{Q}) \).
    Both properties are proved like in the discrete setting
    (cf.~\cite[{Proposition 6.3 and 6.4}]{AbbottEtAl2005DataDifferentiating}),
    with one exception:
    % The sum rule is proved entirely like in the discrete setting \cite[{Proposition~6.3}]{AbbottEtAl2005DataDifferentiating}.
    % The Leibniz rule almost follows the traditional proof (\cite[{Proposition~6.4}]{AbbottEtAl2005DataDifferentiating}),
    for the Leibniz rule,
    one needs to show that isolated points distribute over binary sums in
    \[
      \sum_{s : S} \sum_{t : T} \Isolated{(P_s + Q_t)}
        \simeq
      \sum_{s : S} \sum_{t : T} \Isolated{P_s} + \Isolated{Q_t}
    \]
    This is done via \autoref{isolated-sum-equiv}.
  \end{proof}
\end{proposition}

\todo[inline]{%
  Say something about fixed-points of \( \Der \):
  We expect a trivial fixed-point \( \Der{0} \CartEquiv 0 \),
  but also an analouge of \( \Der{e^x} = e^x \).
  The latter is done in \autoref{bag-fixed-point}.
  But in general, these fixed points are probably not unique,
  given that we can express combinatorial species as containers over \( \FinSet \)
  (thanks Brent, \cite{Yorgey2014CombinatorialSpeciesLabelled}),
  and that for species, differential equations have a lot of solutions \cite{Labelle1986combinatorialdifferentialequations}.
}

Let \( \FinSet \DefEq \sum_{X : \Type} \exists n : \mathbb{N}.\, X \simeq \Op{Fin}(n) \) be the universe of Bishop-finite sets,
together with its forgetful map \( \El \DefEq \Op{fst} : \FinSet \to \Type \).
The container of \emph{bags} is \( \Op{Bag} \DefEq (\MkCont{\FinSet}{\El}) \).
As written, the shapes of this container quantify over all types, hence live in a higher universe.
There are however equivalent small replacements of this type,
such as the one given by \emph{Finster et al.} in \cite[Theorem~25]{FinsterEtAl2021CartesianBicategoryPolynomial}.

\begin{proposition}\label{bag-fixed-point}
  The bag-container is a fixed-point of deriviation:
  there is an equivalence \( \CartIso{\Der{\Op{Bag}}}{\Op{Bag}} \).
  \begin{proof}
    First, note that finite sets are closed under addition and removal of points:
    if \( X \) is finite, then so are \( X + 1 \) and \( X \setminus x \) for all \( x : X \).
    On shapes, we construct an equivalence
    \(
      \sum_{X : \FinSet} \Isolated{\El(X)} \simeq \FinSet
    \)
    from mutually inverse functions \( f \) and \( g \).
    From left to right, define \( f(X, x_0) \DefEq X \setminus x_0 \);
    the other way let \( g(X) \DefEq (X + 1 , \Nothing) \).
    By univalence, finite sets are equal if their carrier types are equivalent,
    so \( f \) and \( g \) are inverses by \autoref{isolated-minus-plus-equiv} and \autoref{maybe-minus-nothing-equiv}.
    Given \( X : \FinSet \) and \( x_0 : \El(X) \), positions are related by the identity equivalence,
    that is
    \(
      \Op{Bag}_{\Ps}(f(X, x_0)) = \El(f(X, x_0)) = X \setminus x_0 = \Der{\Op{Bag}}_{\Ps}(X, x_0)
    \).
  \end{proof}
\end{proposition}

Unlike in classical analysis, where the exponential function is the unique solution to
the differential equation \( f^{\prime} = f \) such that \( f(0) = 1 \),
the situation for containers is more nuanced:
While \( \Op{Bag} \) is a fixed-point of \( \Der \) for which \( { F[\CConst{0}] \CartEquiv \CConst{1} } \),
it is by far the only one:
modulo size issues, the proof of \autoref{bag-fixed-point} goes through for any subuniverse
of types closed under addition and removal of single points
-- for example, type-theoretic ordinals.\todo{Or cardinals???}
This is not entirely unexpected:
containers are closely related to Joyal's \emph{combinatorial species}
(as discussed e.g.~in Yorgey's thesis \cite[67]{Yorgey2014CombinatorialSpeciesLabelled}),
and these are known to have many non-isomorphic solutions even for simple differential equations,
as shown by Labelle in~\cite{Labelle1986combinatorialdifferentialequations}.

\begin{proposition}
  Let \( \Op{Cyc} \) the container of cyclic sets.
  Then \( \CartIso{\Der{\Op{Cyc}}}{\Op{List}} \).
\end{proposition}

\subsection{The Chain Rule}

Stretching the analogy with a derivative of functions further,
we might expect \( \Der \) to satisfy a version of the chain rule
\( (f \circ g)^{\prime} = (f^{\prime} \circ g) \cdot g^{\prime} \).
In our setting, substitution \( \Subst{-}{-} \) takes on the role of composition,
and 

\begin{problem}[note={The lax chain rule}]\label{lax-chain-rule}
  For any two containers \( F, G \), define a morphism
  \[
    \Op{chain}_{F,G} :
    \Cart%
      { \Subst{(\Der{F})}{G} \CTimes \Der{G} }%
      {\Der{(\Subst{F}{G})}}
  \]
\end{problem}
\begin{construction}[note={for \autoref{lax-chain-rule}}]
  Let \( F \JudgeEq (\MkCont{S}{P}) \) and \( G \JudgeEq (\MkCont{T}{Q}) \).
  As usual, we have to construct a map on shapes and an equivalence of positions.
  On shapes, our goal is a map
  \[
    \big(\sum\nolimits_{(s, p) : \sum_{s : S} \Isolated{P_s}} (P_s \setminus p \to T) \big)
      \times
    \sum_{t : T} \Isolated{Q_t}
      \to
    \Big(
      \sum\nolimits_{(s, f) : \sum_{s : S} (P_s \to T)} \Isolated{\big( \sum_{p : P_s} Q_{fp} \big)}
    \Big)
  \]
  Let us first reshape the left side by some equivalences.
  By re-associating the sums, we obtain
  \begin{align*}
      %
    &\mathrel{\hphantom{\simeq}}
      \big(\sum\nolimits_{(s, p) : \sum_{s : S} \Isolated{P_s}} P_s \setminus p \to T \big)
        \times
      \sum_{t : T} \Isolated{Q_t}
    \\
    &\simeq
      \sum\nolimits_{(s, p) : \sum_{s : S} \Isolated{P_s}} \sum\nolimits_{(f, t) : (P_s \setminus p \to T \times T)} \Isolated{Q_t}
  \intertext{%
    By \autoref{graft-equiv}, the type \( (P_s \setminus p \to T \times T) \) is equivalent to \( P_s \to T \),
    thus we simplify to
  }
    &\simeq
      \sum\nolimits_{(s, p) : \sum_{s : S} \Isolated{P_s}} \sum\nolimits_{f : P_s \to T} \Isolated{Q_{fp}}
  \intertext{%
    By re-associating the sum yet again, we are left with
  }
    &\simeq
      \sum\nolimits_{(s, f) : \sum_{s : S} (P_s \to T)} \big( \sum_{p : \Isolated{P_s}} \Isolated{(Q_{fp})} \big)
  \end{align*}
  Denote this equivalence by \( \Op{chain}^{\Op{left}}_{F,G} \).
  Now, the left and the right only differ in
  \begin{align*}
    \sum_{p : \Isolated{P_s}} \Isolated{(Q_{fp})}
      \qquad\text{vs.}\qquad
    \Isolated{\big( \sum_{p : P_s} Q_{fp} \big)}
  \end{align*}
  \Autoref{sigma-isolate} gives us a map
  \(
    \SigmaIsolate_{P_s,Q_{f(\shortminus)}} :
      \sum_{p : \Isolated{P_s}} \Isolated{(Q_{fp})}
        \to
      \Isolated{\big( \sum_{p : P_s} Q_{fp} \big)}
  \),
  hence
  \(
    \cramped{
      \Op{chain}_{F,G}^{\Sh} \DefEq
        \Op{\Sigma}(\Op{id}, \SigmaIsolate_{P_s,Q_{f(\shortminus)}}) \circ \Op{chain}^{\Op{left}}_{F,G}
    }
  \).

  To construct the equivalence on positions,
  let \( s : S \), \( p_0 : \Isolated{P_s} \), \( f : P_s \setminus p_0 \to T \), \( t : T \) and \( q_0 : \Isolated{Q_t} \).
  Our goal becomes to construct an equivalence
  \[
      \big(
        \sum_{p : P_s} Q_{\GraftSyntax{f}{t}(p)}
      \big) \setminus (p_0 , q_0)
    \simeq
      \big(
        \smashoperator{\sum_{p : P_s \setminus p_0}} Q_{f(p)}
      \big)
        +
      (Q_t \setminus q_0),
  \]
  which we obtain from \autoref{is-equiv-sigma-remove}.
\end{construction}

Note that the above proof essentially factors \( \Op{chain}_{F,G} \) into
\[
  \begin{tikzcd}[column sep=large]
    { \Subst{(\Der{F})}{G} \CTimes \Der{G} }%
      \ar[r, -multimap, "\Op{chain}_{F,G}"]
      \ar[d, -multimap, "\sim"{swap}]
      &
    {\Der{(\Subst{F}{G})}}
      \\
    H_0
      \ar[r, -multimap, "\eta"{swap}]
      &
    H_1
      \ar[u, -multimap, "\sim"{swap}]
  \end{tikzcd}
\]
in which
\(
  \eta_{\Sh} :
    \Cart%
      { \sum_{s : S} \sum_{f : P_s \to T} \sum_{p : \Isolated{P_s}} \Isolated{Q_{fp}} }%
      { \sum_{s : S} \sum_{f : P_s \to T} \Isolated{\big( \sum_{p : P_s} Q_{fp} \big)} }
\)
applies \( \SigmaIsolate_{P_s,Q_{f(\shortminus)}} \).
We will make this factorization explicit in the derivation of the chain rule for indexed containers (\autoref{binary-chain-rule}),
but for now we can record the following fact:
\begin{proposition}\label{strong-chain-rule-iff-is-equiv-sigma-isolate}
  Let \( F = (\MkCont{S}{P}) \) and \( G = (\MkCont{T}{Q}) \).
  The following are equivalent propositions:
  \begin{enumerate}
    \item \label{strong-chain-rule-iff-is-equiv-sigma-isolate-1}
      \( \Op{chain}_{F,G} \) is an equivalence of containers
    \item \label{strong-chain-rule-iff-is-equiv-sigma-isolate-2}
        \( \SigmaIsolate_{P_s,Q_{f(\shortminus)}} \) is an equivalence for all \( s : S \) and \( f : P_s \to T \)
    \item \label{strong-chain-rule-iff-is-equiv-sigma-isolate-3}
      For all \( s : S \) and \( f : P_s \to T \), if \( (p, q) : \sum_{p : P_s} Q_{fp} \) is isolated,
      then both \( p \) and \( q \) are isolated.
  \end{enumerate}
  \begin{proof}
    Equivalence of the first two points follows from inspection of the definition of \( \Op{chain} \) in terms of \( \SigmaIsolate \).
    Equivalence with the last point is \autoref{is-equiv-sigma-isolate-iff-isolated-pair}.
  \end{proof}
\end{proposition}

This characterization lets us immediately see in which cases we can and cannot expect a strong chain rule.
Firstly, we recover a strong chain rule for \emph{discrete} containers, as expected by
\cite[{Proposition~6.6}]{AbbottEtAl2005DataDifferentiating}:
\begin{theorem}\label{discrete-strong-chain-rule}
  For discrete containers \( F, G \), \( \Op{chain}_{F,G} \) is an equivalence.
  \begin{proof}
    The positions of \( F \) and \( G \) are discrete,
    so by \autoref{discrete-is-equiv-sigma-isolated}
    \( \SigmaIsolate \) is an equivalence,
    hence is \( \Op{chain}_{F,G} \).
  \end{proof}
\end{theorem}

Secondly, we conclude that globally having a strong chain rule is an inherently classical property:
\begin{theorem}\label{globally-discrete-iff-strong-chain-rule}
  The following are equivalent propositions:
  \begin{enumerate}
    \item \emph{every} type is discrete
    \item for all containers \( F \) and \( G\), \( \Op{chain}_{F,G} \) is an equivalence
  \end{enumerate}
  \begin{proof}
    If every type is discrete, then so is every container, hence the chain rule is always an equivalence by \autoref{discrete-strong-chain-rule}.
    In the other direction,
    use \autoref{discrete-iff-is-equiv-singl-isolate} to show that any given type \( A \) is discrete
    ---
    that is, given some \( a_0 : A \), prove that \( \SigmaIsolate_{A, {a_0 = (\shortminus)}} \) is an equivalence.
    We do so by applying \autoref{strong-chain-rule-iff-is-equiv-sigma-isolate} to containers
    \( F \DefEq (\MkCont{1}{A}) \) and \( G \DefEq (\MkCont{(a_0 : A)}{a_0 = (\shortminus)}) \).
    % In the other direction,
    % use \autoref{is-equiv-sigma-isolate-discrete} to show that any given type \( A \) is discrete
    % ---
    % that is, given some \( B : A \to \Type \), prove that \( \SigmaIsolate_{A,B} \) is an equivalence.
    % We do so by applying \autoref{strong-chain-rule-iff-is-equiv-sigma-isolate} to containers
    % \( F \DefEq (\MkCont{1}{A}) \) and \( G \DefEq (\MkCont{A}{B}) \),
    % and \( s \DefEq \bullet : 1 \) and \( f \DefEq \Op{id} : A \to A \).
  \end{proof}
\end{theorem}

\begin{corollary}
  Assuming a strong chain rule is inconsistent in the presence of non-discrete types:
  \[
    \neg \big( \smashoperator{\prod_{F, G : \Cont}} \Op{isEquiv}(\Op{chain}_{F,G}) \big)
  \]
  \begin{proof}
    The circle \( S^1 \) is provably not discrete: If it were, it would be a set.
  \end{proof}
\end{corollary}

\begin{corollary}
  The following are equivalent:
  \begin{enumerate}
    \item Every set is discrete.
    \item In the 1-category of set-truncated containers, \( \Chain_{F,G} \) is an isomorphism
      for all pairs of containers \( F \) and \( G \).
  \end{enumerate}
  \begin{proof}
    In a 1-category, being an isomorphism is a proposition,
    which
    --- in the category of set-truncated containers ---
    is equivalent to being an equivalence.
    The claim follows by inspection of the proof of \autoref{globally-discrete-iff-strong-chain-rule},
    and ensuring that the same argument applies even when all types involved are 0-truncated.
  \end{proof}
\end{corollary}

We have seen that our definition of derivative behaves nicely even in the presence of non-discrete types,
in that we retain the ways it interacts with sums and products (\autoref{sum-product-rule}).
Its interaction with substitution, however, is more subtle.
While we do obtain a chain rule, it is now \emph{directed} or \emph{lax} (\autoref{lax-chain-rule}),
and whether we can strengthen it to an equivalence depends on the pair of containers involved (\autoref{strong-chain-rule-iff-is-equiv-sigma-isolate}).
Indeed, assuming the latter for any pair of containers is inconsistent in the presence of non-discrete types such
as HITs like the circle \( S^1 \).


\subsection{Derivatives of Fixed Points}

If we interpret containers as blueprints for polymorphic types in a single variable,
we can readily generalize to containers in \( I \) variables, for any \( I : \Type \):
\[
  \Cont_{I} \DefEq \sum_{S : \Type} (I \to S \to \Type)
\]
Ordinary containers correspond to unary containers \( \Cont_{1} \).
Substitution generalizes to an operation \( {-}[{-}] : \Cont_{I+1} \to \Cont_{I} \to \Cont_{I} \).
For any fixed \( F : \Cont_{I+1} \), \( F[-] \) is a wild endofunctor of \( I \)-ary containers.
We encode inductive types as smallest fixed points of substitution.
For some \( F : \Cont_2 \), the container \( {\mu F} : \Cont_1 \) comes with a dedicated
equivalence of containers \( {\mu F} \CartEquiv F \).
This corresponds to \( F \) satisfying the functional equation
\[
  {\mu F}(X) \simeq F(X, {\mu F}(X))
\]
Assuming we have access to \( \W \)-types, recall that we can define a (smallest) fixed point container.
For \( A : \Type \) and \( B : A \to \Type \), \( \W(A, B) : \Type \) has the single constructor
\begin{center}
  \hspace*{\fill}
  {
    \AxiomC{\( a : A \)}
    \AxiomC{\( f : B(a) \to \W(A, B) \)}
    \BinaryInfC{\( \Sup(a, f) : \W(A, B) \)}
    \DisplayProof
  }
  \hspace*{\fill}
\end{center}
A cursor to a position into a \( \W(A, B) \)-tree,
labelled by some \( C : A \to \Type \),
can be defined as an inductive family \( \bar{\W}_{A,B,C} : \W(A,B) \to \Type \) with two constructors, namely
\begin{center}
  \hspace*{\fill}
  {
    \AxiomC{\( c : C(a) \)}
    \UnaryInfC{\( \Op{top}(c) : \bar{\W}_{A, B, C}(\Sup(s, f)) \)}
    \DisplayProof
  }
  \hfill%
  and
  \hfill%
  % \hspace*{\fill}
  % \\[1em]
  % \hspace*{\fill}
  {
    \AxiomC{\( b : B(a) \)}
    \AxiomC{\( w : \bar{\W}_{A,B,C}(f(b)) \)}
    \BinaryInfC{\( \Op{below}(b, w) : \bar{\W}_{A, B, C}(\Sup(s, f)) \)}
    \DisplayProof
  }
  \hspace*{\fill}
\end{center}

% \begin{align*}
%   \Op{top} &: \prod_{a : A} \prod_{f : B(a) \to \W(A, B)} C(a) \to \bar{\W}_{A,B,C}(\Sup(s, f)) \\
%   \Op{below} &: \prod_{a : A} \prod_{f : B(a) \to \W(A, B)} \prod_{b : B(a)} \bar{\W}_{A,B,C}(f(b)) \to \bar{\W}_{A,B,C}(\Sup(s, f))
% \end{align*}


\begin{definition}
  Let \( F \JudgeEq (\MkCont{S}{P}) : \Cont_{I+1} \), define \( {\mu F} \DefEq (\MkCont{S^\mu}{P^\mu}) : \Cont_I \):
  \begin{align*}
    S^\mu &\DefEq \W(S, P_{\Nothing}) \\
    P^\mu_i & \DefEq \bar{\W}_{S,P(\Nothing),P(\Just i)}
  \end{align*}
\end{definition}
\begin{problem}
  Define an equivalence of containers \( \Op{in}_F : F[{\mu F}] \CartEquiv {\mu F} \).
\end{problem}
\begin{problem}\label{mu-rec}
  Define an induction principle for morphisms out of \( \mu \)-containers:
  \begin{center}
    \hspace*{\fill}
    {
      \AxiomC{\( F : \Cont_{I+1} \)}
      \AxiomC{\( G : \Cont_I \)}
      \AxiomC{\( \alpha : \Cart{F[G]}{G} \)}
      \TrinaryInfC{\( \Op{rec}_{F}(\alpha) : \Cart{\mu F}{G} \)}
      \DisplayProof
    }
    \hspace*{\fill}
  \end{center}
\end{problem}

\begin{lemma}\label{is-equiv-from-mu-rec}
  Let \( \alpha : \Cart{\Subst{F}{G}}{G} \).
  If \( \Op{rec}_{F}(\alpha) \) is an equivalence, then so is \( \alpha \).
  \begin{proof}
    Substitution \( \Subst{F}{-} \) preserves equivalences,
    so by 3-for-2 for equivalences of containers, \( \alpha \) on the right is an equivalence:
    \[
      \begin{tikzcd}[column sep=huge]
        \Subst{F}{\mu F} & \Subst{F}{G} \\
        {\mu F}          & G
        \ar[from=1-1, to=1-2, multimap-multimap, "\Subst{F}{\Op{rec}_F(\alpha)}"]
        \ar[from=1-1, to=2-1, multimap-multimap, "\Op{in}_F"{swap}]
        \ar[from=2-1, to=2-2, multimap-multimap, "\Op{rec}_F(\alpha)"{swap}]
        \ar[from=1-2, to=2-2, -multimap, "\alpha"]
      \end{tikzcd}
      \qedhere
    \]
  \end{proof}
\end{lemma}

\begin{definition}[note={Derivative of \( I \)-ary containers}]
  Let \( F \JudgeEq (\MkCont{S}{P}) : \Cont_I \) and \( i : \Isolated{I} \).
  The \( i \)th derivative \( {\Der_i}F \DefEq (\MkCont{S'}{P'}) : \Cont_I \) is defined as follows:
  \begin{align*}
    S' &\DefEq \sum_{s : S} \Isolated{P_i(s)} \\
    P'(j, s, p) &\DefEq
      \begin{cases}
        P_i(s) \setminus p & \text{if } i = j \\
        P_j(s) & \text{otherwise}
      \end{cases}
  \end{align*}
\end{definition}

\begin{remark}
  For an \( (I+1) \)-ary container \( F \), the index \( \Nothing : I + 1 \)
  is always isolated, so we will tacitly write \( \Der{F} \)
  for \( \Der_{\Nothing}(F) : \Cont_I \);
  and similarly in the unary case.
\end{remark}

\begin{problem}
  Construct an action on morphisms
  \[
    \Der_{i} : (\Cart{F}{G}) \to (\Cart{\Der_i{F}}{\Der_i{G}})
  \]
\end{problem}

\begin{proposition}[note={Lax chain rule for binary containers}]\label{binary-chain-rule}
  Let \( F : \Cont_2 \) and \( G : \Cont_1 \).
  There exists a cartesian morphism
  \[
    \Op{chain}_{F,G}
      :
    \Cart%
      {{\Der_0{F}}[G] \CPlus \big( {\Der_1{F}}[G] \CTimes \Der{G} \big)}%
      {\Der{(F[G])}}
  \]
  \begin{construction}
    \renewcommand*{\L}{\Op{L}}
    \newcommand*{\R}{\Op{R}}
    Let \( F \JudgeEq (\MkCont{S}{P}) \), \( G \JudgeEq (\MkCont{T}{Q}) \).
    We define auxiliary containers \( H_1, H_2 \) and factor the morphism into the following:
    \[
      \begin{tikzcd}
        \L \DefEq {{\Der_0{F}}[G] \CPlus \big( {\Der_1{F}}[G] \CTimes \Der{G} \big)}
          \ar[r, -multimap, "\sim"] &
        H_1
          \ar[r, -multimap, "\eta"] &
        H_2
          \ar[r, -multimap, "\sim"] &
        {\Der{(F[G])}}
        \eqcolon \R
      \end{tikzcd}
    \]
    Following the argument in \autoref{lax-chain-rule} and some type yoga,
    we see that type of shapes of the container to the left is equivalent to
    \begin{align}
      U_1 \DefEq
        \sum_{s : S} \sum_{f : P_1(s) \to T} \Isolated{P_0(s)} + \smashoperator{\sum_{p : \Isolated{P_1(s)}}} \Isolated{Q(fp)}
          \label{binary-chain-rule-shape-equiv}
    \end{align}
    Let \( f_1 : {\L}_{\Sh} \simeq U_1 \) be this equivalence, and define \( H_1 \DefEq (\MkCont{U_1}{R_1}) \),
    where \( R_1 \DefEq {\L}_{\Ps} \circ f_1^{\Inv}\).

    On the other side we obtain an equivalence \( f_2 : U_2 \simeq {\R}_{\Sh} \)
    by distributing \( \Isolated{(-)} \) over binary sums:
    \begin{align*}
      U_2
      &\DefEq
      \sum_{s : S} \sum_{f : P_1(s) \to T}
        \Isolated{P_0(s)} + \Isolated{\big( \smashoperator{\sum_{p : P_1(s)}} Q(fp) \big)}
        \\
      &\simeq
      \sum_{s : S} \sum_{f : P_1(s) \to T}
        \Isolated{\big( P_0(s) + \smashoperator{\sum_{p : {P_1(s)}}} Q(fp) \big)}
        \\
      &\simeq
        {\R}_{\Sh}
    \end{align*}
    Again, let \( H_2 \DefEq (\MkCont{U_2}{R_2}) \) where \( R_2 \DefEq {\R}_{\Ps} \circ f_2 \).

    Let us now define \( \eta : H_1 \multimap H_2 \).
    As in \autoref{lax-chain-rule}, define the shape map \( \eta_{\Sh} : U_1 \to U_2 \) using \( \SigmaIsolate_{P_1(s),Q(f\shortminus)} \).
    On positions, the equivalence
    \(
      \eta_{\Ps}(u) : R_2(\eta_{\Sh}(u)) \simeq R_1(u)
    \)
    is defined by cases, depending on which side of the sum \( u : U_1 \) falls.
    Let \( s : S \), \( f : P_1(s) \to T \).
    In case of \( u \JudgeEq (s, f, \Inl{p_0}) \) for \( p_0 : \Isolated{P_0(s)} \), our goal is to give
    \[
      ( \Isolated{P_0(s)} + B ) \setminus \Inl(p_0)
        \simeq
      ( \Isolated{P_0(s)} \setminus p_0 ) + B
      \quad
      (\text{where } B \DefEq {\textstyle \sum_{p : P_1(s)} Q(fp) }),
    \]
    which is an instance of \autoref{sum-remove-equiv}.

    When \( u \JudgeEq (s, f, \Inr(p_1, q)) \) for some \( p_1 : \Isolated{P_1(s)} \) and \( q : \Isolated{Q(fp)} \),
    we rewrite as follows:
    \begin{align}
      R_2(f_2(s , f , \Inr(p_1, q)))
        &\mathrel{\JudgeEq}
          \big( P_0(s) + \smashoperator{\sum_{p : P_1(s)}} Q(f p) \big) \setminus \Inr(p_1, q)
          \notag
          \\
        &\simeq
          P_0(s) + \big( \smashoperator{\sum_{p : P_1(s)}} Q(f p) \big) \setminus (p_1, q)
          \label{binary-chain-rule-pos-equiv-sum-minus}
          \\
        &\simeq
          P_0(s) + \smashoperator{\sum_{p : P_1(s) \setminus p}} Q(f p) + (Q(f\,p_1) \setminus q)
          \label{binary-chain-rule-pos-equiv-sigma-minus}
          \\
        &\mathrel{\JudgeEq}
          R_1(s, f, \Inr{(p_1, q)})
          \notag
    \end{align}
    In \eqref{binary-chain-rule-pos-equiv-sum-minus}, we move the pair \( (p_1, q) \) to the right of the sum (\autoref{sum-remove-equiv}).
    For \eqref{binary-chain-rule-pos-equiv-sigma-minus},
    we split the \( \Sigma \)-type by applying \autoref{is-equiv-sigma-remove}.
    This is justified since both \( p_1 \) and \( q \) are isolated points,
    and together, the pair \( (p_1, q) \) is isolated in \( \sum_{p : P_1(s)} Q(f p) \) by \autoref{is-isolated-pair}.
  \end{construction}
\end{proposition}

For \( F : \Cont_I \), denote by \( \Wk{F} : \Cont_{I+1} \) the inclusion into containers with one more variable
given by
\[
  \Wk{F}_{\Ps}(\Just{i}) \DefEq F_{\Ps}(i), \quad \Wk{F}_{\Ps}(\Nothing) \DefEq 0
\]
For \( i : I \), the \( i \)th projection container is \( \pi_i \DefEq (\MkCont{1}{\mathord{i = {\mathunderscore}}}) : \Cont_I \).
If \( i \) is isolated, the \( i = j \) is a decidable proposition for any \( j : I \);
in this case \( \pi_i \) is equivalent to a container whose \( i \)th type of positions is \( 1 \),
and \( 0 \) for any other direction.

\begin{problem}[note={\( \mu \)-rule}]\label{mu-rule}
  For \( F : \Cont_2 \), define a cartesian morphism
  \[
    \MuRule_F
      :
    \Cart%
      {
        \mu(
          { \Wk{\Der_0{F}[ {\mu F} ]} }
            \CPlus
          (
            \Wk{\Der_1{F}[ {\mu F} ]}
              \CTimes
            \Proj{1}
          )
        )
      }%
      {\Der(\mu F)}
  \]
\end{problem}
  \begin{construction}
    We define the morphism using the induction principle (\autoref{mu-rec}).
    Our goal is to provide some
    \[
      \alpha : \Cart{G[\Der(\mu F)]}{\Der(\mu F)}
    \]
    where \( G \DefEq { \Wk{\Der_0{F}[ {\mu F} ]} } \CPlus ( \Wk{\Der_1{F}[ {\mu F} ]} \CTimes \Proj{1} ) \).
    First note that \( G \) is a container in two variables,
    and substitution into the second replaces \( \Proj{1} \), i.e.\@ there is an equivalence
    \[
      \gamma_{\Highlight{Y}} :
      G[\Highlight{Y}]
        \mathrel{\CartEquiv}
      { \Der_0{F}[ {\mu F} ] } \CPlus ( {\Der_1{F}[ {\mu F} ]} \CTimes \Highlight{Y} )
    \]
    Equipped with this knowledge, we use the chain rule to define \( \alpha \) as the following composite:
    \begin{equation*}
      \begin{tikzcd}[column sep=large]
        {G[\Highlight{\Der(\mu F)}]}
          &
        {\Der(\mu F)}
          \\
        {
          { \Der_0{F}[ {\mu F} ] }
            \CPlus
          (
            {\Der_1{F}[ {\mu F} ]}
              \CTimes
            \Highlight{\Der(\mu F)}
          )
        }
          &
        \Der(F[\mu F])
        \ar[from=1-1, to=2-1, -multimap, "\gamma_{\Highlight{\Der(\mu F)}}"{swap}, "\sim"]
        \ar[from=2-1, to=2-2, -multimap, "\Op{chain}_{F,{\mu\!F}}"{swap}]
        \ar[from=2-2, to=1-2, -multimap, "\Der(\Op{in}_F)"{swap}, "\sim"]
        \ar[from=1-1, to=1-2, dashed, -multimap, "\alpha"]
      \end{tikzcd}
    \end{equation*}
    Lastly, define \( \MuRule_F \DefEq \Op{rec}_{G}(\alpha) : \Cart{ \mu G }{ \Der{(\mu F)} } \).
  \end{construction}

\begin{proposition}
  For any container \( F \),
  \( \MuRule_F \) is an equivalence if and only if \( \Op{chain}_{F,{\mu F}} \) is an equivalence.
  \begin{proof}
    Assume that \( \MuRule_F \) is an equivalence.
    In \autoref{mu-rule}, \( \MuRule_F \) is defined by recursion from some \( \alpha \),
    hence \( \alpha \) is an equivalence by \autoref{is-equiv-from-mu-rec}.
    But \( \alpha \) is just \( \Op{chain}_{F, {\mu F}} \) wedged between two equivalences,
    so the latter is an equivalence as well.
    Conversely, assume \( \Op{chain}_{F,{\mu F}} \) to be an equivalence.
    By \autoref{strong-chain-rule-iff-is-equiv-sigma-isolate}, this is equivalent to isolated pairs
    \( (p_1, \bar{w}) \)
    having isolated components \( p_1 : P_1(s) \) and \( \bar{w} : \bar{\W}(f{p_1}) \),
    for all \( s : S \) and \( f : P_1(s) \to \W_{\!S}(P_1) \).
    This property is exactly what is needed to define a putative inverse on shapes,
    i.e.\@ a map \( \Der{(\mu F)}_{\Sh} \to {(\mu G)}_{\Sh} \).
    That this defines an equivalence of shapes follows by a somewhat tedious,
    but straightforward argument.\todo{The argument is not fully straightforward, one needs has to mix \( \W \)-induction with \( \Graft \)-induction.}
  \end{proof}
\end{proposition}

\printbibliography

\end{document}
